{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc95223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a076e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('full_speech.txt', encoding='utf8')\n",
    "raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcc19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175386cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x85', '\\x96', '\\x97', '\\xa0', 'é', '—']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46a9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x85', '\\x96', '\\x97', '\\xa0', 'é']\n"
     ]
    }
   ],
   "source": [
    "bad_chars = ['(', ')','`','—']\n",
    "for i in range(len(bad_chars)):\n",
    "    raw_text=raw_text.replace(bad_chars[i],\"\")\n",
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d4f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length = 815819\n",
      "No. of Characters = 58\n"
     ]
    }
   ],
   "source": [
    "text_length = len(raw_text)\n",
    "char_length = len(chars)\n",
    "VOCABULARY = char_length\n",
    "print(\"Text Length = \"+ str(text_length))\n",
    "print(\"No. of Characters = \"+ str(char_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3525ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100\n",
    "char_to_int = dict((c, i)for i, c in enumerate(chars))\n",
    "data_X = []\n",
    "data_Y = []\n",
    "\n",
    "for i in range(len(raw_text) - SEQ_LENGTH):\n",
    "    X_text = raw_text[i: i+SEQ_LENGTH]\n",
    "    X = [char_to_int[char] for char in X_text]\n",
    "    data_X.append(X)\n",
    "    Y = raw_text[i + SEQ_LENGTH]\n",
    "    data_Y.append(char_to_int[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c216c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815719, 100, 1)\n",
      "(815719, 58)\n"
     ]
    }
   ],
   "source": [
    "length = len(data_X)\n",
    "data_X = np.array(data_X)\n",
    "data_X = np.reshape(data_X, (data_X.shape[0], data_X.shape[1], 1))\n",
    "data_X = data_X/float(VOCABULARY)\n",
    "\n",
    "data_Y = np.array(data_Y)\n",
    "data_Y = np_utils.to_categorical(data_Y)\n",
    "print(data_X.shape)\n",
    "print(data_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdfa2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be7f3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d2a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM (256, input_shape= (SEQ_LENGTH, 1), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d9736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense (VOCABULARY, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda74f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b10e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "6373/6373 [==============================] - 428s 64ms/step - loss: 2.7582\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.53740, saving model to text_generation.h5\n",
      "Epoch 2/40\n",
      "6373/6373 [==============================] - 409s 64ms/step - loss: 2.1168\n",
      "\n",
      "Epoch 00002: loss improved from 2.53740 to 2.04961, saving model to text_generation.h5\n",
      "Epoch 3/40\n",
      "6373/6373 [==============================] - 409s 64ms/step - loss: 1.88800s - loss: 1.8\n",
      "\n",
      "Epoch 00003: loss improved from 2.04961 to 1.85771, saving model to text_generation.h5\n",
      "Epoch 4/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.77224 - ETA - ETA: 0s - loss: \n",
      "\n",
      "Epoch 00004: loss improved from 1.85771 to 1.75397, saving model to text_generation.h5\n",
      "Epoch 5/40\n",
      "6373/6373 [==============================] - 412s 65ms/step - loss: 1.6981\n",
      "\n",
      "Epoch 00005: loss improved from 1.75397 to 1.68671, saving model to text_generation.h5\n",
      "Epoch 6/40\n",
      "6373/6373 [==============================] - 409s 64ms/step - loss: 1.6424\n",
      "\n",
      "Epoch 00006: loss improved from 1.68671 to 1.63683, saving model to text_generation.h5\n",
      "Epoch 7/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.6034\n",
      "\n",
      "Epoch 00007: loss improved from 1.63683 to 1.59966, saving model to text_generation.h5\n",
      "Epoch 8/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.5694\n",
      "\n",
      "Epoch 00008: loss improved from 1.59966 to 1.56882, saving model to text_generation.h5\n",
      "Epoch 9/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.54112s - \n",
      "\n",
      "Epoch 00009: loss improved from 1.56882 to 1.54183, saving model to text_generation.h5\n",
      "Epoch 10/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.5257\n",
      "\n",
      "Epoch 00010: loss improved from 1.54183 to 1.52267, saving model to text_generation.h5\n",
      "Epoch 11/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.5019\n",
      "\n",
      "Epoch 00011: loss improved from 1.52267 to 1.50412, saving model to text_generation.h5\n",
      "Epoch 12/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4850\n",
      "\n",
      "Epoch 00012: loss improved from 1.50412 to 1.48829, saving model to text_generation.h5\n",
      "Epoch 13/40\n",
      "6373/6373 [==============================] - 409s 64ms/step - loss: 1.46990s - loss: 1.46 - ETA: 0s - loss: 1.469 - ETA: 0s - loss: 1.\n",
      "\n",
      "Epoch 00013: loss improved from 1.48829 to 1.47370, saving model to text_generation.h5\n",
      "Epoch 14/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4561\n",
      "\n",
      "Epoch 00014: loss improved from 1.47370 to 1.45951, saving model to text_generation.h5\n",
      "Epoch 15/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.44963s - l -  - ETA: 0s - loss: 1\n",
      "\n",
      "Epoch 00015: loss improved from 1.45951 to 1.44974, saving model to text_generation.h5\n",
      "Epoch 16/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4339\n",
      "\n",
      "Epoch 00016: loss improved from 1.44974 to 1.43828, saving model to text_generation.h5\n",
      "Epoch 17/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.42370s - l\n",
      "\n",
      "Epoch 00017: loss improved from 1.43828 to 1.42793, saving model to text_generation.h5\n",
      "Epoch 18/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4159\n",
      "\n",
      "Epoch 00018: loss improved from 1.42793 to 1.41891, saving model to text_generation.h5\n",
      "Epoch 19/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4086\n",
      "\n",
      "Epoch 00019: loss improved from 1.41891 to 1.41114, saving model to text_generation.h5\n",
      "Epoch 20/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.4003\n",
      "\n",
      "Epoch 00020: loss improved from 1.41114 to 1.40364, saving model to text_generation.h5\n",
      "Epoch 21/40\n",
      "6373/6373 [==============================] - 411s 64ms/step - loss: 1.39500s - loss: \n",
      "\n",
      "Epoch 00021: loss improved from 1.40364 to 1.39697, saving model to text_generation.h5\n",
      "Epoch 22/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3854\n",
      "\n",
      "Epoch 00022: loss improved from 1.39697 to 1.38845, saving model to text_generation.h5\n",
      "Epoch 23/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3788\n",
      "\n",
      "Epoch 00023: loss improved from 1.38845 to 1.38384, saving model to text_generation.h5\n",
      "Epoch 24/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.37260\n",
      "\n",
      "Epoch 00024: loss improved from 1.38384 to 1.37831, saving model to text_generation.h5\n",
      "Epoch 25/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3706\n",
      "\n",
      "Epoch 00025: loss improved from 1.37831 to 1.37295, saving model to text_generation.h5\n",
      "Epoch 26/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3643 ETA: - ETA: 7s\n",
      "\n",
      "Epoch 00026: loss improved from 1.37295 to 1.36900, saving model to text_generation.h5\n",
      "Epoch 27/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3580\n",
      "\n",
      "Epoch 00027: loss improved from 1.36900 to 1.36248, saving model to text_generation.h5\n",
      "Epoch 28/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3566\n",
      "\n",
      "Epoch 00028: loss improved from 1.36248 to 1.35788, saving model to text_generation.h5\n",
      "Epoch 29/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3490\n",
      "\n",
      "Epoch 00029: loss improved from 1.35788 to 1.35279, saving model to text_generation.h5\n",
      "Epoch 30/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3401\n",
      "\n",
      "Epoch 00030: loss improved from 1.35279 to 1.34894, saving model to text_generation.h5\n",
      "Epoch 31/40\n",
      "6373/6373 [==============================] - 411s 64ms/step - loss: 1.34210s -\n",
      "\n",
      "Epoch 00031: loss improved from 1.34894 to 1.34520, saving model to text_generation.h5\n",
      "Epoch 32/40\n",
      "6373/6373 [==============================] - 495s 78ms/step - loss: 1.3360\n",
      "\n",
      "Epoch 00032: loss improved from 1.34520 to 1.34043, saving model to text_generation.h5\n",
      "Epoch 33/40\n",
      "6373/6373 [==============================] - 586s 92ms/step - loss: 1.3324\n",
      "\n",
      "Epoch 00033: loss improved from 1.34043 to 1.33684, saving model to text_generation.h5\n",
      "Epoch 34/40\n",
      "6373/6373 [==============================] - 581s 91ms/step - loss: 1.3303\n",
      "\n",
      "Epoch 00034: loss improved from 1.33684 to 1.33439, saving model to text_generation.h5\n",
      "Epoch 35/40\n",
      "6373/6373 [==============================] - 579s 91ms/step - loss: 1.32600s - l\n",
      "\n",
      "Epoch 00035: loss improved from 1.33439 to 1.33023, saving model to text_generation.h5\n",
      "Epoch 36/40\n",
      "6373/6373 [==============================] - 583s 91ms/step - loss: 1.3231\n",
      "\n",
      "Epoch 00036: loss improved from 1.33023 to 1.32823, saving model to text_generation.h5\n",
      "Epoch 37/40\n",
      "6373/6373 [==============================] - 585s 92ms/step - loss: 1.3207\n",
      "\n",
      "Epoch 00037: loss improved from 1.32823 to 1.32385, saving model to text_generation.h5\n",
      "Epoch 38/40\n",
      "6373/6373 [==============================] - 514s 81ms/step - loss: 1.31662s - - \n",
      "\n",
      "Epoch 00038: loss improved from 1.32385 to 1.32025, saving model to text_generation.h5\n",
      "Epoch 39/40\n",
      "6373/6373 [==============================] - 410s 64ms/step - loss: 1.3138\n",
      "\n",
      "Epoch 00039: loss improved from 1.32025 to 1.31626, saving model to text_generation.h5\n",
      "Epoch 40/40\n",
      "6373/6373 [==============================] - 411s 64ms/step - loss: 1.3095\n",
      "\n",
      "Epoch 00040: loss improved from 1.31626 to 1.31447, saving model to text_generation.h5\n"
     ]
    }
   ],
   "source": [
    "filepath=\"text_generation.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(data_X, data_Y, epochs = 40, batch_size = 128, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88dfab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'text_generation.h5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "197d6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_text = 'they get five killer terrorists that everybody wanted over there.we gets bergdahl.we get aaa traitor'\n",
    "initial_text = [char_to_int[c] for c in initial_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6693c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tienc in the world trade organization  and i will fight for every child in this country who want to\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "GENERATED_LENGTH = 100\n",
    "test_text = initial_text\n",
    "for i in range(len(initial_text)):\n",
    "    X = np.reshape(test_text, (1, SEQ_LENGTH, 1))\n",
    "    X  = X  / float(VOCABULARY)\n",
    "    Prediction = model.predict(X)\n",
    "    index = np.argmax(Prediction)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    test_text.append(index)\n",
    "    test_text = test_text[1:]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83275e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
